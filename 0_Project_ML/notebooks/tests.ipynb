{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "import os, sys\n",
    "\n",
    "# Helpers\n",
    "abspath = os.path.abspath\n",
    "dirname = os.path.dirname\n",
    "sep = os.sep\n",
    "file_ = os.getcwd()\n",
    "\n",
    "ml_folder = dirname(file_)\n",
    "sys.path.append(ml_folder)\n",
    "\n",
    "from src.utils import mining_data_tb as md\n",
    "from src.utils import visualization_tb as vi\n",
    "from src.utils import folder_tb as fo\n",
    "from src.utils import models as mo\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the data variables are coded (for instance, \"RIAGENDR\" is Gender), we first need to load the variable descriptions. For that, we will create an object with all the info and methods to change names whenever necessary\n",
    "\n",
    "# 1) We create the object\n",
    "vardata = md.variables_data()\n",
    "\n",
    "# 2) We load the info\n",
    "vardata_path = \"data\" + sep + \"6_variables\" + sep + \"0_final_variables.csv\"\n",
    "vardata.load_data(2, vardata_path)\n",
    "\n",
    "# Now we can load the actual dataset we will be using for the ml models\n",
    "\n",
    "# 1) Create object\n",
    "dataset = md.dataset()\n",
    "\n",
    "# 2) Load data\n",
    "folders = [\"1_demographics\", \"2_dietary\", \"3_examination\", \"4_laboratory\", \"5_questionnaire\"]\n",
    "columns_correction = {\n",
    "            \"WTDRD1_x\" : \"WTDRD1\",\n",
    "            \"WTDR2D_x\" : \"WTDR2D\",\n",
    "            \"DRABF_x\" : \"DRABF\",\n",
    "            \"DRDINT_x\" : \"DRDINT\",\n",
    "            \"WTSAF2YR_x\" : \"WTSAF2YR\",\n",
    "            \"LBXHCT_x\" : \"LBXHCT\"\n",
    "        }\n",
    "dataset.load_data(2, folders, columns_correction)\n",
    "\n",
    "# As we can see, it is quite wide. Let's filter by the columns we will actually be using (using our magnificent object)\n",
    "# We will start by trying to predict Asthma\n",
    "features = [\"MCQ160H\", \"RIAGENDR\", \"RIDAGEYR\", \"DR1TCHOL\", \"DR1TTFAT\", \"DR1TSFAT\", \"DR1TSUGR\", \"DR2TCHOL\", \"DR2TTFAT\", \"DR2TSFAT\", \"DR2TSUGR\", \"BPXDI1\", \"BPXSY1\", \"BMXWT\", \"DXDTOPF\", \"BMXWAIST\", \"LBXTR\", \"LBXTC\", \"LBXSGL\"]\n",
    "\n",
    "dataset.filter_columns(features, inplace = True)\n",
    "\n",
    "features_names = vardata.vars_descr_detector(list(dataset.df.columns), 40, True)\n",
    "\n",
    "dataset.df = dataset.df.drop([\"LBXTR\", \"DXDTOPF\"], axis = 1)\n",
    "dataset.df = dataset.df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for the ML models\n",
    "# We won't scale or balance the data for this first round\n",
    "dataset.model_data(split = .2, cv = 3, epochs = 1)\n",
    "\n",
    "# Choose models for test against each other\n",
    "# Same seed of all of them\n",
    "seed = 42\n",
    "\n",
    "log1 = LogisticRegression(n_jobs = -1, random_state = seed)\n",
    "log2 = LogisticRegression(n_jobs = -1, max_iter = 300, random_state = seed)\n",
    "\n",
    "models = [log1, log2]\n",
    "\n",
    "# Models comparison\n",
    "# Ensemble models\n",
    "ensembler = mo.model_ensembler(models)\n",
    "# Load data\n",
    "ensembler.load_data(dataset.X_train, dataset.X_test, dataset.y_train, dataset.y_test, features_names, dataset.kfold)\n",
    "# Train them\n",
    "ensembler.models_tester()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                   Test_score Train_score  \\\n",
       "LogisticRegression(max_iter=300, n_jobs=-1, ran...   0.922305    0.915675   \n",
       "LogisticRegression(n_jobs=-1, random_state=42)       0.920818    0.916233   \n",
       "\n",
       "                                                   Test_score_drop  Accuracy  \\\n",
       "LogisticRegression(max_iter=300, n_jobs=-1, ran...         0.00724  0.922305   \n",
       "LogisticRegression(n_jobs=-1, random_state=42)            0.005004  0.920818   \n",
       "\n",
       "                                                   Precision    Recall  \\\n",
       "LogisticRegression(max_iter=300, n_jobs=-1, ran...  0.617021  0.131818   \n",
       "LogisticRegression(n_jobs=-1, random_state=42)      0.574468  0.122727   \n",
       "\n",
       "                                                    F1_score  \\\n",
       "LogisticRegression(max_iter=300, n_jobs=-1, ran...  0.217228   \n",
       "LogisticRegression(n_jobs=-1, random_state=42)      0.202247   \n",
       "\n",
       "                                                           Confusion_matrix  \n",
       "LogisticRegression(max_iter=300, n_jobs=-1, ran...  [[2452, 18], [191, 29]]  \n",
       "LogisticRegression(n_jobs=-1, random_state=42)      [[2450, 20], [193, 27]]  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Test_score</th>\n      <th>Train_score</th>\n      <th>Test_score_drop</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1_score</th>\n      <th>Confusion_matrix</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>LogisticRegression(max_iter=300, n_jobs=-1, random_state=42)</th>\n      <td>0.922305</td>\n      <td>0.915675</td>\n      <td>0.00724</td>\n      <td>0.922305</td>\n      <td>0.617021</td>\n      <td>0.131818</td>\n      <td>0.217228</td>\n      <td>[[2452, 18], [191, 29]]</td>\n    </tr>\n    <tr>\n      <th>LogisticRegression(n_jobs=-1, random_state=42)</th>\n      <td>0.920818</td>\n      <td>0.916233</td>\n      <td>0.005004</td>\n      <td>0.920818</td>\n      <td>0.574468</td>\n      <td>0.122727</td>\n      <td>0.202247</td>\n      <td>[[2450, 20], [193, 27]]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "ensembler.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Succesfully saved'"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "path_to_save = fo.path_to_folder(2, \"models\") + \"first_attempt\"\n",
    "ensembler.models_saver(path_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = mo.ml_model(log1)\n",
    "my_model.load_data(dataset.X_train, dataset.X_test, dataset.y_train, dataset.y_test, features_names, dataset.kfold)\n",
    "my_model.ml_trainer()\n",
    "my_model.ml_tester()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Succesfully saved'"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "my_model.model_saver(fo.path_to_folder(2, \"models\") + \"second_attempt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['model_comparison_noscale_nobalance.csv',\n",
       " 'first_attempt',\n",
       " 'second_attempt.pkl']"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "os.listdir(fo.path_to_folder(2, \"models\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(n_jobs=-1, random_state=42)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "loaded_model = joblib.load(fo.path_to_folder(2, \"models\") + \"second_attempt.pkl\")\n",
    "loaded_model"
   ]
  },
  {
   "source": [
    "# Let's prepare the data and choose a model\n",
    "\n",
    "# 1) Prepare data for ml models\n",
    "# For this, we have an useful method in our dataset object. We'll try a basic split and validation, without making any further change to the data (for this attempt)\n",
    "dataset.model_data(split = .2, cv = 5, epochs = 1)\n",
    "\n",
    "# 2) Choose model\n",
    "model = LogisticRegression(n_jobs = -1, max_iter = 300)\n",
    "\n",
    "# 3) We create a ml_model object and load the data\n",
    "my_model = md.ml_model(model)\n",
    "\n",
    "# Load data\n",
    "my_model.load_data(dataset.X_train, dataset.X_test, dataset.y_train, dataset.y_test, features_names, dataset.kfold)\n",
    "\n",
    "# 4) We train the model\n",
    "my_model.ml_trainer()"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "my_model.model.intercept_"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "path_to_save = fo.path_to_folder(2, \"models\") + \"First_attempt.pkl\"\n",
    "joblib.dump(my_model.model, path_to_save)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "loaded_model = joblib.load(path_to_save)\n",
    "loaded_model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "loaded_model.intercept_"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}