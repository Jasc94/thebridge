{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "import os, sys\n",
    "\n",
    "# Helpers\n",
    "abspath = os.path.abspath\n",
    "dirname = os.path.dirname\n",
    "sep = os.sep\n",
    "file_ = os.getcwd()\n",
    "\n",
    "ml_folder = dirname(file_)\n",
    "sys.path.append(ml_folder)\n",
    "\n",
    "from src.utils import mining_data_tb as md\n",
    "from src.utils import visualization_tb as vi\n",
    "from src.utils import folder_tb as fo\n",
    "from src.utils import models as mo\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       MCQ160H  RIDAGEYR  DR1TCHOL  DR1TTFAT  DR1TSFAT  DR1TSUGR  DR2TCHOL  \\\n",
       "SEQN                                                                         \n",
       "83732        0        62     138.0     79.24    23.430     42.31     635.0   \n",
       "83733        0        53     407.0     77.91    25.722    180.84     773.0   \n",
       "\n",
       "       DR2TTFAT  DR2TSFAT  DR2TSUGR  BPXDI1  BPXSY1  BMXWT  BMXWAIST  LBXTC  \\\n",
       "SEQN                                                                          \n",
       "83732    121.59    40.420    118.40    70.0   128.0   94.8     101.1  173.0   \n",
       "83733    154.55    32.969     34.52    88.0   146.0   90.4     107.9  265.0   \n",
       "\n",
       "       LBXSGL  Female  Male  \n",
       "SEQN                         \n",
       "83732    94.0       0     1  \n",
       "83733    94.0       0     1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MCQ160H</th>\n      <th>RIDAGEYR</th>\n      <th>DR1TCHOL</th>\n      <th>DR1TTFAT</th>\n      <th>DR1TSFAT</th>\n      <th>DR1TSUGR</th>\n      <th>DR2TCHOL</th>\n      <th>DR2TTFAT</th>\n      <th>DR2TSFAT</th>\n      <th>DR2TSUGR</th>\n      <th>BPXDI1</th>\n      <th>BPXSY1</th>\n      <th>BMXWT</th>\n      <th>BMXWAIST</th>\n      <th>LBXTC</th>\n      <th>LBXSGL</th>\n      <th>Female</th>\n      <th>Male</th>\n    </tr>\n    <tr>\n      <th>SEQN</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>83732</th>\n      <td>0</td>\n      <td>62</td>\n      <td>138.0</td>\n      <td>79.24</td>\n      <td>23.430</td>\n      <td>42.31</td>\n      <td>635.0</td>\n      <td>121.59</td>\n      <td>40.420</td>\n      <td>118.40</td>\n      <td>70.0</td>\n      <td>128.0</td>\n      <td>94.8</td>\n      <td>101.1</td>\n      <td>173.0</td>\n      <td>94.0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>83733</th>\n      <td>0</td>\n      <td>53</td>\n      <td>407.0</td>\n      <td>77.91</td>\n      <td>25.722</td>\n      <td>180.84</td>\n      <td>773.0</td>\n      <td>154.55</td>\n      <td>32.969</td>\n      <td>34.52</td>\n      <td>88.0</td>\n      <td>146.0</td>\n      <td>90.4</td>\n      <td>107.9</td>\n      <td>265.0</td>\n      <td>94.0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# As the data variables are coded (for instance, \"RIAGENDR\" is Gender), we first need to load the variable descriptions. For that, we will create an object with all the info and methods to change names whenever necessary\n",
    "\n",
    "# 1) We create the object\n",
    "vardata = md.variables_data()\n",
    "\n",
    "# 2) We load the info\n",
    "vardata_path = \"data\" + sep + \"6_variables\" + sep + \"0_final_variables.csv\"\n",
    "vardata.load_data(2, vardata_path)\n",
    "\n",
    "# Now we can load the actual dataset we will be using for the ml models\n",
    "\n",
    "# 1) Create object\n",
    "dataset = md.dataset()\n",
    "\n",
    "# 2) Load data\n",
    "folders = [\"1_demographics\", \"2_dietary\", \"3_examination\", \"4_laboratory\", \"5_questionnaire\"]\n",
    "columns_correction = {\n",
    "            \"WTDRD1_x\" : \"WTDRD1\",\n",
    "            \"WTDR2D_x\" : \"WTDR2D\",\n",
    "            \"DRABF_x\" : \"DRABF\",\n",
    "            \"DRDINT_x\" : \"DRDINT\",\n",
    "            \"WTSAF2YR_x\" : \"WTSAF2YR\",\n",
    "            \"LBXHCT_x\" : \"LBXHCT\"\n",
    "        }\n",
    "dataset.load_data(2, folders, columns_correction)\n",
    "\n",
    "# As we can see, it is quite wide. Let's filter by the columns we will actually be using (using our magnificent object)\n",
    "# We will start by trying to predict Asthma\n",
    "features = [\"MCQ160H\", \"RIAGENDR\", \"RIDAGEYR\", \"DR1TCHOL\", \"DR1TTFAT\", \"DR1TSFAT\", \"DR1TSUGR\", \"DR2TCHOL\", \"DR2TTFAT\", \"DR2TSFAT\", \"DR2TSUGR\", \"BPXDI1\", \"BPXSY1\", \"BMXWT\", \"DXDTOPF\", \"BMXWAIST\", \"LBXTR\", \"LBXTC\", \"LBXSGL\"]\n",
    "\n",
    "dataset.filter_columns(features, inplace = True)\n",
    "\n",
    "features_names = vardata.vars_descr_detector(list(dataset.df.columns), 40, True)\n",
    "\n",
    "dataset.drop_columns([\"LBXTR\", \"DXDTOPF\"])\n",
    "dataset.drop_nans()\n",
    "\n",
    "mapper = {1 : \"Male\", 2 : \"Female\"}\n",
    "dataset.dummies_transform(\"RIAGENDR\", mapper)\n",
    "\n",
    "dataset.df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "variable = \"RIAGENDR\"\n",
    "mapper = {1 : \"Male\", 2 : \"Female\"}\n",
    "dataset.df.loc[:, variable] = dataset.df.loc[:, variable].map(mapper)\n",
    "dataset.df = pd.get_dummies(dataset.df, prefix = \"\", prefix_sep = \"\", columns = [variable])\n",
    "dataset.df.head()"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "def dummies_transform(df, variable, mapper):\n",
    "    df.loc[:, variable] = df.loc[:, variable].map(mapper)\n",
    "    df = pd.get_dummies(df, prefix = \"\", prefix_sep = \"\", columns = [variable])\n",
    "    return df\n",
    "\n",
    "variable = \"RIAGENDR\"\n",
    "mapper = {1 : \"Male\", 2 : \"Female\"}\n",
    "dataset.df = dummies_transform(dataset.df, variable, mapper)\n",
    "dataset.df.head()"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "test = dataset.df\n",
    "test.RIAGENDR = test.RIAGENDR.replace([1, 2], [\"Male\", \"Female\"])\n",
    "test = pd.get_dummies(test, prefix = \"\", prefix_sep = \"\", columns = [\"RIAGENDR\"])\n",
    "test.head()"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1    1386\n",
       "0    1304\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "loaded_model = joblib.load(fo.path_to_folder(2, \"models\" + sep + \"model_comparison_scale_balance\") + \"LogisticRegression(max_iter=300, n_jobs=-1, random_state=42).pkl\")\n",
    "\n",
    "dataset.model_data(split = .2, cv = 3, epochs = 1)\n",
    "pd.Series(loaded_model.predict(dataset.X_test)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['MCQ160H',\n",
       " 'RIAGENDR: Gender of the participant.',\n",
       " 'RIDAGEYR: Age in years of the participant at the time of screening. Individuals 80 and over are topcoded at 80 years of age.',\n",
       " 'DR1TCHOL: Cholesterol (mg)',\n",
       " 'DR1TTFAT: Total fat (gm)',\n",
       " 'DR1TSFAT: Total saturated fatty acids (gm)',\n",
       " 'DR1TSUGR: Total sugars (gm)',\n",
       " 'DR2TCHOL: Cholesterol (mg)',\n",
       " 'DR2TTFAT: Total fat (gm)',\n",
       " 'DR2TSFAT: Total saturated fatty acids (gm)',\n",
       " 'DR2TSUGR: Total sugars (gm)',\n",
       " 'BPXDI1: Diastolic:  Blood pressure (first reading) mm Hg',\n",
       " 'BPXSY1: Systolic:  Blood pressure (first reading) mm Hg',\n",
       " 'BMXWT: Weight (kg)',\n",
       " 'BMXWAIST: Waist Circumference (cm)',\n",
       " 'LBXTC: Total Cholesterol (mg/dL)',\n",
       " 'LBXSGL: Glucose, refrigerated serum (mg/dL)']"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "vardata.vars_descr_detector([\"MCQ160H\", \"RIAGENDR\", \"RIDAGEYR\", \"DR1TCHOL\", \"DR1TTFAT\", \"DR1TSFAT\", \"DR1TSUGR\", \"DR2TCHOL\", \"DR2TTFAT\", \"DR2TSFAT\", \"DR2TSUGR\", \"BPXDI1\", \"BPXSY1\", \"BMXWT\", \"BMXWAIST\", \"LBXTC\", \"LBXSGL\"], nom_included = True)"
   ]
  },
  {
   "source": [
    "# Prepare data for the ML models\n",
    "# We won't scale or balance the data for this first round\n",
    "dataset.model_data(split = .2, cv = 3, epochs = 1)\n",
    "\n",
    "# Choose models for test against each other\n",
    "# Same seed of all of them\n",
    "seed = 42\n",
    "\n",
    "log1 = LogisticRegression(n_jobs = -1, random_state = seed)\n",
    "log2 = LogisticRegression(n_jobs = -1, max_iter = 300, random_state = seed)\n",
    "\n",
    "models = [log1, log2]\n",
    "\n",
    "# Models comparison\n",
    "# Ensemble models\n",
    "ensembler = mo.model_ensembler(models)\n",
    "# Load data\n",
    "ensembler.load_data(dataset.X_train, dataset.X_test, dataset.y_train, dataset.y_test, features_names, dataset.kfold)\n",
    "# Train them\n",
    "ensembler.models_tester()\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "ensembler.metrics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Succesfully saved'"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "#path_to_save = fo.path_to_folder(2, \"models\") + \"first_attempt\"\n",
    "#ensembler.models_saver(path_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.model_data(split = .2, cv = 3, epochs = 1)\n",
    "my_model = mo.ml_model(log1)\n",
    "my_model.load_data(dataset.X_train, dataset.X_test, dataset.y_train, dataset.y_test, features_names, dataset.kfold)\n",
    "my_model.ml_trainer()\n",
    "my_model.ml_tester()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Succesfully saved'"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "#my_model.model_saver(fo.path_to_folder(2, \"models\") + \"second_attempt\")"
   ]
  },
  {
   "source": [
    "os.listdir(fo.path_to_folder(2, \"models\"))"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "loaded_model = joblib.load(fo.path_to_folder(2, \"models\") + \"second_attempt.pkl\")\n",
    "loaded_model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Let's prepare the data and choose a model\n",
    "\n",
    "# 1) Prepare data for ml models\n",
    "# For this, we have an useful method in our dataset object. We'll try a basic split and validation, without making any further change to the data (for this attempt)\n",
    "dataset.model_data(split = .2, cv = 5, epochs = 1)\n",
    "\n",
    "# 2) Choose model\n",
    "model = LogisticRegression(n_jobs = -1, max_iter = 300)\n",
    "\n",
    "# 3) We create a ml_model object and load the data\n",
    "my_model = md.ml_model(model)\n",
    "\n",
    "# Load data\n",
    "my_model.load_data(dataset.X_train, dataset.X_test, dataset.y_train, dataset.y_test, features_names, dataset.kfold)\n",
    "\n",
    "# 4) We train the model\n",
    "my_model.ml_trainer()"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "my_model.model.intercept_"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "path_to_save = fo.path_to_folder(2, \"models\") + \"First_attempt.pkl\"\n",
    "joblib.dump(my_model.model, path_to_save)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "loaded_model = joblib.load(path_to_save)\n",
    "loaded_model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "loaded_model.intercept_"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}