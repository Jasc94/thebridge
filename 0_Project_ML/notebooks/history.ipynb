{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url)\n",
    "\n",
    "soup = bs(r.text, \"lxml\")\n",
    "\n",
    "table = soup.find(id = \"GridView1\")\n",
    "rows = table.find_all(\"tr\")\n",
    "\n",
    "var_names = []\n",
    "var_descrs = []\n",
    "file_names = []\n",
    "file_descrs = []\n",
    "start_years = []\n",
    "end_years = []\n",
    "components = []\n",
    "constraints = []\n",
    "\n",
    "\n",
    "for row in range(1, len(rows)):\n",
    "    var_name, var_descr, file_name, file_descr, start_year, end_year, component, constraint = rows[row].find_all(\"td\")\n",
    "\n",
    "    var_names.append(var_name.text)\n",
    "    var_descrs.append(var_descr.text)\n",
    "    file_names.append(file_name.text)\n",
    "    file_descrs.append(file_descr.text)\n",
    "    start_years.append(start_year.text)\n",
    "    end_years.append(end_year.text)\n",
    "    components.append(component.text)\n",
    "    constraints.append(constraint.text)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(list(zip(var_names, var_descrs, file_names, file_descrs, start_years, end_years, components, constraints)), columns = [\"var_name\", \"var_descr\", \"file_name\", \"file_descr\", \"start_year\", \"end_year\", \"component\", \"constraint\"])\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_descr_detector(var_name, vars_df):\n",
    "    descr = vars_df[vars_df[\"vAr_nAmE\"] == var_name][\"var_descr\"].values[0]\n",
    "    return descr\n",
    "\n",
    "def n_rows(df, n_columns):\n",
    "    columns = list(df.columns)\n",
    "\n",
    "    if len(columns) % n_columns == 0:\n",
    "        axes_rows = len(columns) // n_columns\n",
    "    else:\n",
    "        axes_rows = (len(columns) // n_columns) + 1\n",
    "\n",
    "    return axes_rows\n",
    "\n",
    "def multi_axes_plotter(df, n_columns, kind, figsize, var_names = None):\n",
    "    n_rows_ = n_rows(df, n_columns)\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows_, n_columns, figsize = figsize)\n",
    "    count = 0\n",
    "\n",
    "    for row in range(axes.shape[0]):\n",
    "        for column in range(axes.shape[1]):\n",
    "            if kind == \"strip\":\n",
    "                sns.stripplot(y = df.iloc[:, count], ax = axes[row][column])\n",
    "            elif kind == \"dist\":\n",
    "                sns.distplot(df.iloc[:, count], ax = axes[row][column])\n",
    "            elif kind == \"box\":\n",
    "                sns.boxplot(df.iloc[:, count], ax = axes[row][column])\n",
    "            else:\n",
    "                sns.histplot(df.iloc[:, count], ax = axes[row][column], bins = 30)\n",
    "\n",
    "            try:\n",
    "                axes[row][column].set(xlabel = var_descr_detector(df.iloc[:, count].name, var_names))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            if (count + 1) < df.shape[1]:\n",
    "                count += 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Callback to pass in to the compiler\n",
    "class my_callback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs = None):\n",
    "        if (epoch + 1) % 100 == 0 and epoch > 0:\n",
    "            print(f\"Epoch number {epoch + 1} done\")\n",
    "\n",
    "########################### DATA MANIPULATION ###########################\n",
    "##### Total time points\n",
    "def data(N):\n",
    "    t= np.arange(0,N)\n",
    "    x= (2*np.sin(0.02*t)*np.sin(0.003*t))+0.5*np.random.normal(size=N)\n",
    "\n",
    "    return t, x\n",
    "\n",
    "##### Batches\n",
    "def batch_calculator(t, x, batch_size):\n",
    "    t_batch = t[:batch_size]\n",
    "    x_batch = x[:batch_size]\n",
    "\n",
    "    return t_batch, x_batch\n",
    "\n",
    "# Train_test splitter\n",
    "def train_test(t_batch, x_batch, split):\n",
    "    split_ = round(split * len(x_batch))\n",
    "\n",
    "    t_train, t_test = t_batch[:split_], t_batch[split_:]\n",
    "    x_train, x_test = x_batch[:split_], x_batch[split_:]\n",
    "\n",
    "    return t_train, t_test, x_train, x_test\n",
    "\n",
    "########################### MODELING ###########################\n",
    "##### Neural network\n",
    "def model_creator():\n",
    "    model = Sequential([\n",
    "        layers.LSTM(units = 128, input_shape = (1, 4), activation = \"relu\"),\n",
    "        layers.Dense(32, activation = \"relu\"),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(loss = \"mean_squared_error\", optimizer = RMSprop(lr = .001), metrics = [\"mse\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "##### Looper\n",
    "def model_trainer(model, train, test):\n",
    "    # Data preprocessing\n",
    "    train = np.append(train,np.repeat(train[-1,], step))\n",
    "    test = np.append(test,np.repeat(test[-1,], step))\n",
    "\n",
    "    X_train, y_train = convert_to_matrix(train, step)\n",
    "    X_test, y_test = convert_to_matrix(test, step)\n",
    "\n",
    "    # Reshaping to fit into the model\n",
    "    X_train, X_test = X_train.reshape(len(X_train), 1, 4), X_test.reshape(len(X_test), 1, 4)\n",
    "\n",
    "    # Model training\n",
    "    model_history = model.fit(X_train, y_train, epochs = 100, batch_size = 16, callbacks = [my_callback()], verbose = 0)\n",
    "\n",
    "    # Predictions\n",
    "    train_prediction = model.predict(X_train)\n",
    "    test_prediction = model.predict(X_test)\n",
    "\n",
    "    return model_history.history, train_prediction, test_prediction\n",
    "\n",
    "########################### DATA VISUALIZATION ###########################\n",
    "# To plot everything together\n",
    "def plotter(model_history, t_train, t_test, x_train, x_test, train_prediction, test_prediction):\n",
    "    fig = plt.figure(figsize = (14, 8), constrained_layout=True)\n",
    "    gs = fig.add_gridspec(2, 2)\n",
    "\n",
    "    # Actual data\n",
    "    ax1 = fig.add_subplot(gs[0, :-1])\n",
    "    ax1.set_title('Actual data')\n",
    "    ax1.plot(t_train, x_train, c = 'blue')\n",
    "    ax1.plot(t_test, x_test, c = 'orange', alpha = 0.7)\n",
    "    ax1.legend(['Train','Test'])\n",
    "    ax1.axvline(t_train[-1], c=\"r\")\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Predictions\n",
    "    ax2 = fig.add_subplot(gs[0, -1])\n",
    "    ax2.set_title('Predictions')\n",
    "    ax2.plot(t_train, train_prediction, c = 'blue')\n",
    "    ax2.plot(t_test, test_prediction, c = 'orange', alpha = 0.7)\n",
    "    ax2.legend(['Train','Test'])\n",
    "    ax2.axvline(t_train[-1], c=\"r\")\n",
    "    ax2.grid(True)\n",
    "\n",
    "    # Loss function\n",
    "    ax3 = fig.add_subplot(gs[1, :])\n",
    "    ax3.set_title('RMSE loss over epochs')\n",
    "    ax3.plot(np.sqrt(model_history['loss']),c='k',lw=2)\n",
    "    ax3.grid(True)\n",
    "    ax3.set_xlabel(\"Epochs\",fontsize=14)\n",
    "    ax3.set_ylabel(\"Root-mean-squared error\",fontsize=14)\n",
    "\n",
    "    return fig"
   ]
  }
 ]
}