{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "import os, sys\n",
    "\n",
    "# Relative paths\n",
    "dirname = os.path.dirname\n",
    "sep = os.sep\n",
    "\n",
    "ml_folder = dirname(os.getcwd())\n",
    "sys.path.append(ml_folder)\n",
    "\n",
    "from src.utils import mining_data_tb as md\n",
    "from src.utils import visualization_tb as vi\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ml_model:\n",
    "    def __init__(self, model):\n",
    "        # Data\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        self.features = None\n",
    "        self.kfold = None\n",
    "\n",
    "        # Training\n",
    "        self.model = model\n",
    "        self.train_scores = []\n",
    "        self.val_scores = []\n",
    "        self.train_set_structures = []\n",
    "        self.val_set_structures = []\n",
    "        self.feature_importances = None\n",
    "\n",
    "        # Test\n",
    "        self.train_score = None\n",
    "        self.test_score = None\n",
    "        self.train_structure = None\n",
    "        self.test_structure = None\n",
    "        self.prediction = None\n",
    "        self.cm = None        \n",
    "\n",
    "    #########\n",
    "    def model_data(self, df, features, split, cv, epochs = 1, scaler = False, balance = None, seed = 42): \n",
    "        self.features = features\n",
    "\n",
    "        ### Independent variables\n",
    "        X = np.array(df.iloc[:, 1:])\n",
    "\n",
    "        ### Dependent variable\n",
    "        y = np.array(df.iloc[:, 0])\n",
    "\n",
    "        ### Data scaling\n",
    "        if scaler:\n",
    "            scaler = StandardScaler()\n",
    "            X = scaler.fit_transform(X)\n",
    "\n",
    "        ### Train-test\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size = split, random_state = seed)\n",
    "\n",
    "        ### Balancing data\n",
    "        if balance != None:\n",
    "            sm = SMOTE(sampling_strategy = balance, random_state = seed, n_jobs = -1)\n",
    "            self.X_train, self.y_train = sm.fit_resample(self.X_train, self.y_train)\n",
    "\n",
    "        ### Cross validation\n",
    "        self.kfold = RepeatedStratifiedKFold(n_splits = cv, n_repeats = epochs, random_state = seed)\n",
    "\n",
    "    #########\n",
    "    def ml_trainer(self):\n",
    "        count = 1\n",
    "\n",
    "        for (train, val) in self.kfold.split(self.X_train, self.y_train):\n",
    "            # Train-Validation sets\n",
    "            x_t, y_t = self.X_train[train], self.y_train[train]\n",
    "            x_v, y_v = self.X_train[val], self.y_train[val]\n",
    "\n",
    "\n",
    "            # Internal structure\n",
    "            y_t_unique, y_t_counts = np.unique(y_t, return_counts=True)\n",
    "            y_v_unique, y_v_counts = np.unique(y_v, return_counts=True)\n",
    "\n",
    "            self.train_set_structures.append(dict(zip(y_t_unique, y_t_counts / len(y_t))))\n",
    "            self.train_set_structures.append(dict(zip(y_v_unique, y_v_counts / len(y_v))))\n",
    "\n",
    "            # Training\n",
    "            self.model.fit(x_t, y_t)\n",
    "\n",
    "            # Scores\n",
    "            train_score = self.model.score(x_t, y_t)\n",
    "            val_score = self.model.score(x_v, y_v)\n",
    "\n",
    "            self.train_scores.append(train_score)\n",
    "            self.val_scores.append(val_score)\n",
    "\n",
    "            print(f\"\\n-- Model {count} --\")\n",
    "            print(\"-\" * 25)\n",
    "            print(\"Set structure:\")\n",
    "            print(\"Train structure:\", dict(zip(y_t_unique, y_t_counts / len(y_t))))\n",
    "            print(\"Validation structure:\", dict(zip(y_v_unique, y_v_counts / len(y_v))))\n",
    "            print(\"-\" * 25)\n",
    "            print(\">train score:\", train_score)\n",
    "            print(\">test score:\", val_score)\n",
    "            print(\"#\" * 75)\n",
    "\n",
    "            count += 1\n",
    "\n",
    "        try:\n",
    "            importances = self.model.feature_importances_\n",
    "            feature_importances = list(zip(self.features, importances))\n",
    "\n",
    "            self.feature_importances = pd.DataFrame(feature_importances, columns = [\"features\", \"importance\"]).sort_values(by = \"importance\", ascending = False)\n",
    "\n",
    "            #return train_scores, val_scores, feature_importances_df\n",
    "        \n",
    "        except:\n",
    "            pass\n",
    "            #return train_scores, val_scores\n",
    "\n",
    "    def ml_tester(self):\n",
    "        # Internal structure\n",
    "        y_train_unique, y_train_counts = np.unique(self.y_train, return_counts=True)\n",
    "        y_test_unique, y_test_counts = np.unique(self.y_test, return_counts=True)\n",
    "\n",
    "        self.train_structure =dict(zip(y_train_unique, y_train_counts / len(self.y_train) * 100))\n",
    "        self.test_structure = dict(zip(y_test_unique, y_test_counts / len(self.y_test) * 100))\n",
    "\n",
    "        # Scores\n",
    "        self.train_score = model.score(self.X_train, self.y_train)\n",
    "        self.test_score = model.score(self.X_test, self.y_test)\n",
    "\n",
    "        # Prediction\n",
    "        self.prediction = model.predict(self.X_test)\n",
    "\n",
    "        # Confusion matrix\n",
    "        self.cm = metrics.confusion_matrix(self.y_test, self.prediction)\n",
    "\n",
    "    def ml_predictions(self, to_predict):\n",
    "        new_predictions = self.model.predict(to_predict)\n",
    "        return new_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vardata = md.variables_data()\n",
    "var_data_path = \"data\" + sep + \"6_variables\" + sep + \"0_final_variables.csv\"\n",
    "\n",
    "vardata.var_data(2, var_data_path)"
   ]
  },
  {
   "source": [
    "data = md.dataset()\n",
    "data.read_all_data(0, [\"1_demographics\", \"2_dietary\", \"3_examination\", \"4_laboratory\", \"5_questionnaire\"])\n",
    "data.concatenate_all_dfs()\n",
    "data.merge_dfs()\n",
    "\n",
    "columns_correction = {\n",
    "            \"WTDRD1_x\" : \"WTDRD1\",\n",
    "            \"WTDR2D_x\" : \"WTDR2D\",\n",
    "            \"DRABF_x\" : \"DRABF\",\n",
    "            \"DRDINT_x\" : \"DRDINT\",\n",
    "            \"WTSAF2YR_x\" : \"WTSAF2YR\",\n",
    "            \"LBXHCT_x\" : \"LBXHCT\"\n",
    "        }\n",
    "data.clean_columns(columns_correction)\n",
    "data.heart_disease()\n",
    "\n",
    "df = data.full_df"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(29285, 951)"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3754, 19)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "df2 = df.loc[:, [\"MCQ010\", \"RIAGENDR\", \"RIDAGEYR\", \"DR1TCHOL\", \"DR1TTFAT\", \"DR1TSFAT\", \"DR1TSUGR\", \"DR2TCHOL\", \"DR2TTFAT\", \"DR2TSFAT\", \"DR2TSUGR\", \"BPXDI1\", \"BPXSY1\", \"BMXWT\", \"DXDTOPF\", \"BMXWAIST\", \"LBXTR\", \"LBXTC\", \"LBXSGL\"]]\n",
    "df2 = df2.dropna()\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = vardata.vars_descr_detector(list(df2.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "-- Model 1 --\n",
      "-------------------------\n",
      "Set structure:\n",
      "Train structure: {1.0: 0.16651865008880995, 2.0: 0.8325932504440497, 9.0: 0.0008880994671403197}\n",
      "Validation structure: {1.0: 0.1677762982689747, 2.0: 0.8322237017310253}\n",
      "-------------------------\n",
      ">train score: 0.9995559502664298\n",
      ">test score: 0.8308921438082557\n",
      "###########################################################################\n",
      "\n",
      "-- Model 2 --\n",
      "-------------------------\n",
      "Set structure:\n",
      "Train structure: {1.0: 0.1669626998223801, 2.0: 0.8325932504440497, 9.0: 0.0004440497335701599}\n",
      "Validation structure: {1.0: 0.16644474034620507, 2.0: 0.8322237017310253, 9.0: 0.0013315579227696406}\n",
      "-------------------------\n",
      ">train score: 1.0\n",
      ">test score: 0.8229027962716379\n",
      "###########################################################################\n",
      "\n",
      "-- Model 3 --\n",
      "-------------------------\n",
      "Set structure:\n",
      "Train structure: {1.0: 0.1669626998223801, 2.0: 0.8325932504440497, 9.0: 0.0004440497335701599}\n",
      "Validation structure: {1.0: 0.16644474034620507, 2.0: 0.8322237017310253, 9.0: 0.0013315579227696406}\n",
      "-------------------------\n",
      ">train score: 1.0\n",
      ">test score: 0.8322237017310253\n",
      "###########################################################################\n",
      "\n",
      "-- Model 4 --\n",
      "-------------------------\n",
      "Set structure:\n",
      "Train structure: {1.0: 0.16688859298712827, 2.0: 0.8322237017310253, 9.0: 0.000887705281846427}\n",
      "Validation structure: {1.0: 0.16666666666666666, 2.0: 0.8333333333333334}\n",
      "-------------------------\n",
      ">train score: 1.0\n",
      ">test score: 0.832\n",
      "###########################################################################\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_jobs = -1, random_state = 42)\n",
    "\n",
    "my_model = ml_model(model)\n",
    "my_model.model_data(df2, features, split = 0.2, cv = 4, epochs = 1)\n",
    "my_model.ml_trainer()\n",
    "my_model.ml_tester()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = my_model.X_test[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.])"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "my_model.ml_predictions(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}